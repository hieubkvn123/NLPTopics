{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Tensorflow dependencies ###\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "### NLTK dependencies ### \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "### Others ###\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Some constants ###\n",
    "BASE_DIR = \"./\" # \"/content/drive/My Drive/\"\n",
    "WEIGHTS_DIR = os.path.join(BASE_DIR, \"weights\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "BASIC_CNN_MODEL_NAME = \"basic_cnn\"\n",
    "COMPLEX_CNN_MODEL_NAME = \"complex_cnn\"\n",
    "BASIC_BIRNN_MODEL_NAME = \"basic_birnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preparing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Took 24.807793140411377 seconds to preprocess data from ../data/sentiment_train.tsv\n",
      "[INFO] Took 10.443564414978027 seconds to preprocess data from ../data/sentiment_test.tsv\n"
     ]
    }
   ],
   "source": [
    "### 1. Loading data from files and preprocessing ###\n",
    "def en_contraction_expand(sentence):\n",
    "    # Dictionary of English Contractions\n",
    "    contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n",
    "    contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    \n",
    "    return contractions_re.sub(replace, sentence)\n",
    "\n",
    "def filter_stopwords(text):\n",
    "    ### Stopword removal using the nltk way ###\n",
    "    stop_words = set(stopwords.words('english')) # Assuming all nltk data is installed\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered = [lemmatizer.lemmatize(w) for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    filtered_sentence = ' '.join(filtered)\n",
    "    return filtered_sentence\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    # 1. expand contraction for english\n",
    "    sentence = en_contraction_expand(sentence)\n",
    "    \n",
    "    # 2. lowercasing text\n",
    "    sentence = sentence.strip().lower()\n",
    "    \n",
    "    # 3. Digits removal\n",
    "    sentence = re.sub('\\w*\\d\\w*','', sentence)\n",
    "\n",
    "    # 4. Punctuations removal\n",
    "    sentence = re.sub('[%s]' % re.escape(string.punctuation), '', sentence)\n",
    "    \n",
    "    # 5. Extra spaces removal\n",
    "    sentence = re.sub(' +',' ', sentence)\n",
    "    \n",
    "    # 5. filter stopwords \n",
    "    sentence = filter_stopwords(sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def load_data_from_tsv(data_file, test=False):\n",
    "    start = time.time()\n",
    "    data = pd.read_table(data_file, header=0)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    dropped_cols = [\"PhraseId\", \"SentenceId\"]\n",
    "    data.drop(dropped_cols, inplace=True, axis=1)\n",
    "    \n",
    "    sentences = data['Phrase'].values\n",
    "    \n",
    "    if(test):\n",
    "        sentiments = None\n",
    "    else:\n",
    "        sentiments = data['Sentiment'].values\n",
    "    \n",
    "    sentences = [preprocess_sentence(x) for x in sentences]\n",
    "    sentences = np.array(sentences)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f'[INFO] Took {end - start} seconds to preprocess data from {data_file}')\n",
    "    \n",
    "    return sentences, sentiments\n",
    "\n",
    "X_train, Y_train = load_data_from_tsv(\"../data/sentiment_train.tsv\")\n",
    "X_test, Y_test  = load_data_from_tsv(\"../data/sentiment_test.tsv\", test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of sentences in training set : 156060\n",
      "[INFO] Number of sentences in testing set  : 66292\n",
      "[INFO] Maximum sentence length in          : 30\n",
      "[INFO] Vocabulary size                     : 5000\n"
     ]
    }
   ],
   "source": [
    "### 2. Vectorizing data for sentiment analysis ###\n",
    "tokenizer = Tokenizer(num_words=5000, char_level=False, oov_token=\"PAD\") # 0 is a reserved index\n",
    "tokenizer.fit_on_texts(np.concatenate([X_train, X_test]))\n",
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "test_seq  = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "### Sequence padding ###\n",
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding = 'post')\n",
    "\n",
    "train_seq = pad(train_seq)\n",
    "test_seq  = pad(test_seq, length=train_seq.shape[-1])\n",
    "\n",
    "vocab_size = np.max(np.concatenate([train_seq, test_seq])) + 1\n",
    "num_classes = len(np.unique(Y_train))\n",
    "\n",
    "print(f'[INFO] Number of sentences in training set : {train_seq.shape[0]}')\n",
    "print(f'[INFO] Number of sentences in testing set  : {test_seq.shape[0]}')\n",
    "print(f'[INFO] Maximum sentence length in          : {train_seq.shape[1]}')\n",
    "print(f'[INFO] Vocabulary size                     : {vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building basic CNN model with 1 Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"basic_cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 30, 1)]           0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 30, 1, 32)         160000    \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 30, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 188,261\n",
      "Trainable params: 188,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[INFO] Saving model into ./models/basic_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "def make_simple_cnn_model(input_shape, vocab_size):\n",
    "    inputs = Input(shape=input_shape[1:])\n",
    "    embs   = Embedding(vocab_size, 32, input_length=input_shape[1])(inputs)\n",
    "    embs   = Reshape(target_shape=(input_shape[1], 32))(embs)\n",
    "    \n",
    "    conv1d = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(embs)\n",
    "    pool1d = MaxPool1D(pool_size=2)(conv1d)\n",
    "    \n",
    "    # return_sequences : whether to return the full sequence of output or only the last output in the sequence\n",
    "    # return_sequences is defaulted as False.\n",
    "    rnn    = LSTM(64, return_sequences=False, dropout=0.2,recurrent_dropout=0.2)(pool1d)\n",
    "    logits = Dense(num_classes)(rnn)\n",
    "    output = Activation(\"softmax\")(logits)\n",
    "    \n",
    "    model  = Model(inputs=inputs, outputs=output, name=BASIC_CNN_MODEL_NAME)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "train_seq = train_seq.reshape(-1, train_seq.shape[1], 1)\n",
    "test_seq  = test_seq.reshape(-1, test_seq.shape[1], 1)\n",
    "model = make_simple_cnn_model(train_seq.shape, vocab_size)\n",
    "\n",
    "print(model.summary())\n",
    "print(f'[INFO] Saving model into {MODELS_DIR}/{BASIC_CNN_MODEL_NAME}.h5')\n",
    "model.save(f'{MODELS_DIR}/{BASIC_CNN_MODEL_NAME}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 1.0821 - accuracy: 0.5722 - val_loss: 0.9531 - val_accuracy: 0.6212\n",
      "Epoch 2/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 0.9157 - accuracy: 0.6360 - val_loss: 0.9232 - val_accuracy: 0.6370\n",
      "Epoch 3/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 0.8594 - accuracy: 0.6570 - val_loss: 0.9017 - val_accuracy: 0.6401\n",
      "Epoch 4/10\n",
      "3252/3252 [==============================] - 76s 24ms/step - loss: 0.8175 - accuracy: 0.6755 - val_loss: 0.8774 - val_accuracy: 0.6497\n",
      "Epoch 5/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 0.7856 - accuracy: 0.6880 - val_loss: 0.8811 - val_accuracy: 0.6477\n",
      "Epoch 6/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 0.7591 - accuracy: 0.7000 - val_loss: 0.8840 - val_accuracy: 0.6503\n",
      "Epoch 7/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 0.7360 - accuracy: 0.7090 - val_loss: 0.8935 - val_accuracy: 0.6516\n",
      "Epoch 8/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 0.7192 - accuracy: 0.7159 - val_loss: 0.8897 - val_accuracy: 0.6548\n",
      "Epoch 9/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 0.7016 - accuracy: 0.7216 - val_loss: 0.9031 - val_accuracy: 0.6494\n",
      "Epoch 10/10\n",
      "3252/3252 [==============================] - 77s 24ms/step - loss: 0.6882 - accuracy: 0.7281 - val_loss: 0.9005 - val_accuracy: 0.6492\n",
      "[INFO] Saving model weights into ./weights/basic_cnn.weights.hdf5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train_seq, Y_train, test_size=0.3333)\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=10, batch_size=64)\n",
    "\n",
    "print(f'[INFO] Saving model weights into {WEIGHTS_DIR}/{BASIC_CNN_MODEL_NAME}.weights.hdf5')\n",
    "model.save_weights(f'{WEIGHTS_DIR}/{BASIC_CNN_MODEL_NAME}.weights.hdf5')\n",
    "\n",
    "### Visualizing training results ###\n",
    "train_loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "\n",
    "train_acc = model.history.history['accuracy']\n",
    "val_acc = model.history.history['val_accuracy']\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "ax[0].plot(train_loss, label='Train Loss', color='blue')\n",
    "ax[0].plot(val_loss, label='Validation Loss', color='orange')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(train_acc, label='Train Accuracy', color='blue')\n",
    "ax[1].plot(val_acc, label='Validation Accuracy', color='orange')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build more complex CNN with multiple Conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"complex_cnn\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 30, 128)      640000      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 30, 128)      0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 30, 32)       8224        reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 30, 32)       12320       reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 30, 32)       16416       reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 30, 32)       20512       reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 30, 32)       24608       reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 30, 32)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 30, 32)       0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 30, 32)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 30, 32)       0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 30, 32)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 30, 32)       0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 30, 32)       0           leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 30, 32)       0           leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 30, 32)       0           leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 30, 32)       0           leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 150, 32)      0           dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 128)          82432       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 5)            645         lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 5)            0           dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 805,157\n",
      "Trainable params: 805,157\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "[INFO] Saving model into ./models/complex_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "def make_complex_cnn_model(input_shape, vocab_size):\n",
    "    kernel_sizes = [2,3,4,5,6]\n",
    "    inputs = Input(shape=input_shape[1:])\n",
    "    embs   = Embedding(vocab_size, 128, input_length=input_shape[1])(inputs)\n",
    "    embs   = Reshape(target_shape=(input_shape[1], 128))(embs)\n",
    "    \n",
    "    convs = []\n",
    "    for kernel_size in kernel_sizes:\n",
    "        conv1d = Conv1D(filters=32, kernel_size=kernel_size, padding='same', activation='relu',\n",
    "                       kernel_regularizer=l1(1e-4))(embs)\n",
    "        # pool1d = MaxPool1D(pool_size=2)(conv1d)\n",
    "        relu = LeakyReLU(0.02)(conv1d)\n",
    "        output = Dropout(0.3)(relu)\n",
    "\n",
    "        convs.append(output)\n",
    "    \n",
    "    concat = Concatenate(axis=1)(convs)\n",
    "    # return_sequences : whether to return the full sequence of output or only the last output in the sequence\n",
    "    # return_sequences is defaulted as False.\n",
    "    rnn    = LSTM(128, return_sequences=False, dropout=0.2,recurrent_dropout=0.2)(concat)\n",
    "    logits = Dense(num_classes)(rnn)\n",
    "    output = Activation(\"softmax\")(logits)\n",
    "    \n",
    "    model  = Model(inputs=inputs, outputs=output, name=COMPLEX_CNN_MODEL_NAME)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = make_complex_cnn_model(train_seq.shape, vocab_size)\n",
    "print(model.summary())\n",
    "\n",
    "print(f\"[INFO] Saving model into {MODELS_DIR}/{COMPLEX_CNN_MODEL_NAME}.h5\")\n",
    "model.save(f'{MODELS_DIR}/{COMPLEX_CNN_MODEL_NAME}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1626/1626 [==============================] - 370s 227ms/step - loss: 1.1674 - accuracy: 0.5493 - val_loss: 1.0654 - val_accuracy: 0.5872\n",
      "Epoch 2/10\n",
      "1626/1626 [==============================] - 366s 225ms/step - loss: 1.0266 - accuracy: 0.6094 - val_loss: 0.9759 - val_accuracy: 0.6281\n",
      "Epoch 3/10\n",
      "1626/1626 [==============================] - 371s 228ms/step - loss: 0.9382 - accuracy: 0.6406 - val_loss: 0.9456 - val_accuracy: 0.6352\n",
      "Epoch 4/10\n",
      "1626/1626 [==============================] - 368s 226ms/step - loss: 0.9005 - accuracy: 0.6535 - val_loss: 0.9383 - val_accuracy: 0.6340\n",
      "Epoch 5/10\n",
      "1511/1626 [==========================>...] - ETA: 22s - loss: 0.8707 - accuracy: 0.6665"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f0955c8a4628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3333\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[INFO] Saving model weights into {WEIGHTS_DIR}/{COMPLEX_CNN_MODEL_NAME}.weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{WEIGHTS_DIR}/{COMPLEX_CNN_MODEL_NAME}.weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train_seq, Y_train, test_size=0.3333)\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=10, batch_size=64)\n",
    "\n",
    "print(f'[INFO] Saving model weights into {WEIGHTS_DIR}/{COMPLEX_CNN_MODEL_NAME}.weights.hdf5')\n",
    "model.save_weights(f'{WEIGHTS_DIR}/{COMPLEX_CNN_MODEL_NAME}.weights.hdf5')\n",
    "\n",
    "### Visualizing training results ###\n",
    "train_loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "\n",
    "train_acc = model.history.history['accuracy']\n",
    "val_acc = model.history.history['val_accuracy']\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "ax[0].plot(train_loss, label='Train Loss', color='blue')\n",
    "ax[0].plot(val_loss, label='Validation Loss', color='orange')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(train_acc, label='Train Accuracy', color='blue')\n",
    "ax[1].plot(val_acc, label='Validation Accuracy', color='orange')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basic_birnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 30, 1)]           0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 30, 1, 32)         160000    \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 30, 32)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 30, 128)           49664     \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 309,125\n",
      "Trainable params: 309,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[INFO] Saving model into ./models/basic_birnn.h5\n"
     ]
    }
   ],
   "source": [
    "# Build a simple Bidirectional LSTM model\n",
    "def make_simple_cnn_model(input_shape, vocab_size):\n",
    "    inputs = Input(shape=input_shape[1:])\n",
    "    embs   = Embedding(vocab_size, 32, input_length=input_shape[1])(inputs)\n",
    "    embs   = Reshape(target_shape=(input_shape[1], 32))(embs)\n",
    "    \n",
    "    rnn = Bidirectional(LSTM(64, return_sequences=True))(embs)\n",
    "    rnn = Bidirectional(LSTM(64))(rnn)\n",
    "    \n",
    "    logits = Dense(5)(rnn)\n",
    "    output = Activation(\"sigmoid\")(logits)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output, name=BASIC_BIRNN_MODEL_NAME)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "train_seq = train_seq.reshape(-1, train_seq.shape[1], 1)\n",
    "test_seq  = test_seq.reshape(-1, test_seq.shape[1], 1)\n",
    "model = make_simple_cnn_model(train_seq.shape, vocab_size)\n",
    "\n",
    "print(model.summary())\n",
    "print(f'[INFO] Saving model into {MODELS_DIR}/{BASIC_BIRNN_MODEL_NAME}.h5')\n",
    "model.save(f'{MODELS_DIR}/{BASIC_BIRNN_MODEL_NAME}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1626/1626 [==============================] - 10s 6ms/step - loss: 1.0777 - accuracy: 0.5697 - val_loss: 0.9431 - val_accuracy: 0.6186\n",
      "Epoch 2/10\n",
      "1626/1626 [==============================] - 10s 6ms/step - loss: 0.9097 - accuracy: 0.6343 - val_loss: 0.9085 - val_accuracy: 0.6335\n",
      "Epoch 3/10\n",
      "1626/1626 [==============================] - 10s 6ms/step - loss: 0.8624 - accuracy: 0.6533 - val_loss: 0.8933 - val_accuracy: 0.6432\n",
      "Epoch 4/10\n",
      "1626/1626 [==============================] - 10s 6ms/step - loss: 0.8298 - accuracy: 0.6649 - val_loss: 0.8874 - val_accuracy: 0.6429\n",
      "Epoch 5/10\n",
      "1626/1626 [==============================] - 10s 6ms/step - loss: 0.8057 - accuracy: 0.6762 - val_loss: 0.8920 - val_accuracy: 0.6469\n",
      "Epoch 6/10\n",
      "1626/1626 [==============================] - 10s 6ms/step - loss: 0.7845 - accuracy: 0.6838 - val_loss: 0.8935 - val_accuracy: 0.6442\n",
      "Epoch 7/10\n",
      "1452/1626 [=========================>....] - ETA: 0s - loss: 0.7628 - accuracy: 0.6931"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f0955c8a4628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3333\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[INFO] Saving model weights into {WEIGHTS_DIR}/{COMPLEX_CNN_MODEL_NAME}.weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{WEIGHTS_DIR}/{COMPLEX_CNN_MODEL_NAME}.weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train_seq, Y_train, test_size=0.3333)\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=10, batch_size=64)\n",
    "\n",
    "print(f'[INFO] Saving model weights into {WEIGHTS_DIR}/{BASIC_BIRNN_MODEL_NAME}.weights.hdf5')\n",
    "model.save_weights(f'{WEIGHTS_DIR}/{BASIC_BIRNN_MODEL_NAME}.weights.hdf5')\n",
    "\n",
    "### Visualizing training results ###\n",
    "train_loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "\n",
    "train_acc = model.history.history['accuracy']\n",
    "val_acc = model.history.history['val_accuracy']\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "\n",
    "ax[0].plot(train_loss, label='Train Loss', color='blue')\n",
    "ax[0].plot(val_loss, label='Validation Loss', color='orange')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(train_acc, label='Train Accuracy', color='blue')\n",
    "ax[1].plot(val_acc, label='Validation Accuracy', color='orange')\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
